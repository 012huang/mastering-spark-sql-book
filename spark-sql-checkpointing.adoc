== Dataset Checkpointing

*Dataset Checkpointing* is a feature of Spark SQL to truncate a logical query plan that is specifically designed for highly iterative data algorithms (e.g. Spark MLlib that uses Spark SQL's `Dataset` API for data manipulation).

[NOTE]
====
Checkpointing is actually a feature of Spark Core (that Spark SQL uses for distributed computations) that allows a driver to be restarted on failure with previously computed state of a distributed computation described as an `RDD`.

Checkpointing truncates the lineage of a RDD to be checkpointed.

Dataset checkpointing in Spark SQL uses checkpointing to truncate the lineage of the underlying RDD of a `Dataset` to be checkpointed.
====

Checkpointing can be eager or lazy per `eager` flag of <<checkpoint, checkpoint>> operator. *Eager checkpointing* is the default checkpointing and happens immediately when requested. *Lazy checkpointing* does not and will only happen when an action is executed.

[[checkpoint-directory]]
Using Dataset checkpointing requires that you specify the *checkpoint directory*. The directory stores the checkpoint files for RDDs to be checkpointed. Use <<sparkcontext-setCheckpointDir, SparkContext.setCheckpointDir>> to set the path to a checkpoint directory.

Checkpointing can be <<localCheckpoint, local>> or <<checkpoint, reliable>> which defines how reliable the <<checkpoint-directory, checkpoint directory>> is. *Local checkpointing* uses executor storage to write checkpoint files to and due to the executor lifecycle is considered unreliable. *Reliable checkpointing* uses a reliable data storage like Hadoop HDFS.

.Dataset Checkpointing Types
[cols="1,^1,^2",options="header",width="100%"]
|===
|
| Eager
| Lazy

^| *Reliable*
| <<checkpoint, checkpoint>>
| <<checkpoint, checkpoint(eager = false)>>

^| *Local*
| <<localCheckpoint, localCheckpoint>>
| <<localCheckpoint, localCheckpoint(eager = false)>>
|===

[[logging]]
[TIP]
====
Enable `INFO` logging level for `org.apache.spark.rdd.ReliableRDDCheckpointData` logger to see what happens while an RDD is checkpointed.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.rdd.ReliableRDDCheckpointData=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

[source, scala]
----
import org.apache.spark.sql.functions.rand
val nums = spark.range(5).withColumn("random", rand()).filter($"random" > 0.5)

scala> println(nums.queryExecution.toRdd.toDebugString)
(8) MapPartitionsRDD[2] at toRdd at <console>:27 []
 |  MapPartitionsRDD[1] at toRdd at <console>:27 []
 |  ParallelCollectionRDD[0] at toRdd at <console>:27 []

// Remember to set the checkpoint directory
scala> nums.checkpoint
org.apache.spark.SparkException: Checkpoint directory has not been set in the SparkContext
  at org.apache.spark.rdd.RDD.checkpoint(RDD.scala:1548)
  at org.apache.spark.sql.Dataset.checkpoint(Dataset.scala:594)
  at org.apache.spark.sql.Dataset.checkpoint(Dataset.scala:539)
  ... 49 elided

spark.sparkContext.setCheckpointDir("/tmp/checkpoints")

scala> println(spark.sparkContext.getCheckpointDir.get)
file:/tmp/checkpoints/310a6163-a75f-438d-a19c-65076c5fa80f

val numsCheckpointed = nums.checkpoint
scala> println(numsCheckpointed.queryExecution.toRdd.toDebugString)
(8) MapPartitionsRDD[6] at toRdd at <console>:27 []
 |  MapPartitionsRDD[4] at checkpoint at <console>:26 []
 |  ReliableCheckpointRDD[5] at checkpoint at <console>:26 []

// Set org.apache.spark.rdd.ReliableRDDCheckpointData logger to INFO
// to see what happens while an RDD is checkpointed
// Let's use log4j API
import org.apache.log4j.{Level, Logger}
Logger.getLogger("org.apache.spark.rdd.ReliableRDDCheckpointData").setLevel(Level.INFO)

scala> nums.checkpoint
18/03/22 19:37:13 INFO ReliableRDDCheckpointData: Done checkpointing RDD 7 to file:/tmp/checkpoints/310a6163-a75f-438d-a19c-65076c5fa80f/rdd-7, new parent is RDD 8
res6: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: bigint, random: double]
----

=== [[checkpoint]] Checkpointing Dataset -- `checkpoint` Operator

[source, scala]
----
checkpoint(): Dataset[T]  // <1>
checkpoint(eager: Boolean): Dataset[T]  // <2>
// private
checkpoint(eager: Boolean, reliableCheckpoint: Boolean): Dataset[T]
----
<1> `eager` and `reliableCheckpoint` flags enabled
<2> `reliableCheckpoint` flag enabled

NOTE: `checkpoint` is an experimental operator and the API is evolving towards becoming stable.

`checkpoint`...FIXME

Internally, `checkpoint` requests link:spark-sql-Dataset.adoc#queryExecution[QueryExecution] (of the `Dataset`) to link:spark-sql-QueryExecution.adoc#toRdd[generate an RDD of internal binary rows] (aka `internalRdd`) and then requests the RDD to make a copy of all the rows (by adding a `MapPartitionsRDD`).

Depending on `reliableCheckpoint` flag, `checkpoint` marks the RDD for (reliable) checkpointing (`true`) or local checkpointing (`false`).

With `eager` flag on, `checkpoint` counts the number of records in the RDD (by executing `RDD.count`) that gives the effect of immediate eager checkpointing.

`checkpoint` requests link:spark-sql-Dataset.adoc#queryExecution[QueryExecution] (of the `Dataset`) for link:spark-sql-QueryExecution.adoc#executedPlan[optimized physical plan] (the plan is used to get the link:spark-sql-SparkPlan.adoc#outputPartitioning[outputPartitioning] and link:spark-sql-SparkPlan.adoc#outputOrdering[outputOrdering] for the result `Dataset`).

In the end, `checkpoint` link:spark-sql-Dataset.adoc#ofRows[creates a DataFrame] with a new link:spark-sql-LogicalRDD.adoc#creating-instance[logical plan node for scanning data from an RDD of InternalRows] (`LogicalRDD`).

=== [[sparkcontext-setCheckpointDir]] Specyfing Checkpoint Directory -- `SparkContext.setCheckpointDir` Method

[source, scala]
----
SparkContext.setCheckpointDir(directory: String)
----

`setCheckpointDir` sets the <<checkpoint-directory, checkpoint directory>>.

Internally, `setCheckpointDir`...FIXME

=== [[localCheckpoint]] Locally Checkpointing Dataset -- `localCheckpoint` Method

[source, scala]
----
localCheckpoint(): Dataset[T] // <1>
localCheckpoint(eager: Boolean): Dataset[T]
----
<1> `eager` flag enabled with `reliableCheckpoint` flag disabled

`localCheckpoint` simply executes <<checkpoint, checkpoint>> with the input `eager` flag and `reliableCheckpoint` flag disabled.
